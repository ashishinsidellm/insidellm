import logging
import uuid

from insidellm import InsideLLMClient, track_function_execution, track_llm_call

# --- Basic Setup ---
# Configure logging for demonstration purposes
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize the InsideLLMClient
# Replace with your actual API key and endpoint if not using environment variables
client = InsideLLMClient()

# Start a new trace run
# It's good practice to use a unique run_id, e.g., generated by uuid
run_id = str(uuid.uuid4())
client.start_run(run_id=run_id)

logger.info(f"Started run with ID: {run_id}")


# --- Placeholder Functions for Decorator Examples ---
# The @track_function_execution decorator will automatically log an event
# to InsideLLM when this function is called.
# We can also provide a custom name for the event.
@track_function_execution(client, function_name="my_custom_string_concatenator")
def example_tracked_function(a: str, b: str) -> str:
    """
    A simple function that concatenates two strings.
    Its execution is tracked by InsideLLM.
    An event named 'my_custom_string_concatenator' will be logged.
    """
    logger.info(
        f"Inside example_tracked_function with args: a='{a}', b='{b}'"
    )
    result = a + " " + b
    logger.info(f"example_tracked_function result: '{result}'")
    return result


# The @track_llm_call decorator will automatically log LLM_REQUEST and LLM_RESPONSE events.
# We specify `model_name` and `provider` which are important metadata for LLM calls.
@track_llm_call(client, model_name="mock-llm", provider="mock_provider")
def example_llm_call_function(prompt: str, temperature: float = 0.7):
    """
    A function that simulates a call to an LLM.
    Its execution, including prompt and response, will be tracked by InsideLLM.
    This will result in an LLM_REQUEST event before the function body executes,
    and an LLM_RESPONSE event after it completes, associated with "mock-llm".
    """
    logger.info(
        f"Inside example_llm_call_function with prompt: '{prompt}', temperature: {temperature}"
    )
    # Simulate LLM processing:
    # In a real scenario, this is where you would interact with an actual LLM API.
    # The decorator handles capturing the prompt from the arguments.
    mock_response = f"This is a mock LLM response to your prompt: '{prompt}' (temp: {temperature})"
    logger.info(f"Simulated LLM response: '{mock_response}'")

    # The decorator will automatically capture the returned string as the LLM's output.
    # If you need to return more complex data or metadata (like token counts, cost),
    # the decorated function can return a dictionary with specific keys
    # (e.g., 'output', 'input_tokens', 'output_tokens', 'cost').
    # For this example, a simple string response is sufficient.
    return mock_response


if __name__ == "__main__":
    logger.info("Running decorator examples...")

    # --- Demonstrating @track_function_execution ---
    logger.info("\n--- Demonstrating @track_function_execution ---")
    # Calling the tracked function.
    # InsideLLM will log an event for this function call under the name 'my_custom_string_concatenator'.
    tracked_result = example_tracked_function("Hello", "Decorator")
    logger.info(f"Call to example_tracked_function completed. Result: '{tracked_result}'")
    logger.info("An event for 'my_custom_string_concatenator' should have been logged by InsideLLM.")


    # Example usage of the LLM call tracked function
    # --- Demonstrating @track_llm_call ---
    logger.info("\n--- Demonstrating @track_llm_call ---")
    llm_prompt = "Explain the theory of relativity in simple terms."
    # Calling the LLM tracked function.
    # InsideLLM will log LLM_REQUEST and LLM_RESPONSE events for this call.
    llm_response = example_llm_call_function(llm_prompt, temperature=0.5)
    logger.info(f"Call to example_llm_call_function completed. Response: '{llm_response}'")
    logger.info("LLM_REQUEST and LLM_RESPONSE events for 'mock-llm' (provider: 'mock_provider') should have been logged by InsideLLM.")

    logger.info("\nDecorator examples finished.")
    # The run will be automatically ended when the client is garbage collected
    # or can be explicitly ended with client.end_run()
    # It's good practice to explicitly end the run.
    client.end_run()
    logger.info(f"Run {run_id} ended.")
